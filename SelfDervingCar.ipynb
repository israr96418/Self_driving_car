{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c981df",
   "metadata": {},
   "source": [
    "# Self Deriving Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6aeab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete proceesing data.txt [0.         0.         0.         ... 0.03874631 0.03874631 0.03874631]\n",
      "train_data:  (36324,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "from scipy import misc\n",
    "import pandas as pd\n",
    "\n",
    "# Perform simple Eploratory data analysis(EDA) on Steering angle\n",
    "\n",
    "DataFolder = 'D:\\DataSet for ML\\Selfdriving_dataset'\n",
    "Train_file = os.path.join(DataFolder, 'data.txt')\n",
    "# split data into train and test\n",
    "# 80% shuffle to train-->means 20 mint video(convert into images-->as we known that video is sequence of images)\n",
    "\n",
    "splits = 0.8\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "start = 0\n",
    "stop = 45405\n",
    "with open(Train_file, encoding='UTF-8') as fp:\n",
    "    for line in islice(fp,start,stop):\n",
    "        path , angle = line.strip().split()\n",
    "        full_path = os.path.join(DataFolder,path)\n",
    "        x.append(full_path)\n",
    "        \n",
    "#         convert angle from degree into radian\n",
    "        y.append(float(angle) * pi/ 180)\n",
    "\n",
    "y = np.array(y)\n",
    "print('Complete proceesing data.txt',y)\n",
    "\n",
    "# here we split data into train(80%-->20mint video) and test(20%-->5 mint video)\n",
    "split_index = int(len(y)*0.8)\n",
    "train_y = y[:split_index]\n",
    "print(\"train_data: \",train_y.shape)\n",
    "test_y = y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd64fdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36324,)\n",
      "(9081,)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e364a277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_y, bins=50, color='green', histtype='step');\n",
    "plt.hist(test_y, bins=50,  color='red', histtype='step');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925edae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19355701 -0.18832103 -0.17592919 ...  0.03874631  0.03874631\n",
      "  0.03874631]\n"
     ]
    }
   ],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "facef256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# islice(iterable,start, stop, step)\n",
    "# we must passed at least 2 argumnet\n",
    "for i in islice(range(20),1):\n",
    "    print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58069cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10233397",
   "metadata": {},
   "source": [
    "# Simple Mean BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7d836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE(MEAN):  0.1911477887692512\n",
      "Test MSE(zero) 0.19091206441753242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# take mean of train_y and then we used it as predictor for test_y\n",
    "train_mean_y = np.mean(train_y)\n",
    "\n",
    "# simple Regression prooblem --> input sequence of images and output realvaue\n",
    "# So the performance matric for regression problem is ---> MSE(mean squared error)\n",
    "\n",
    "# Ideal value for MSE = 0(impossible for machine)\n",
    "print(\"Test MSE(MEAN): \", np.mean(np.square(test_y-train_mean_y)))\n",
    "print(\"Test MSE(zero)\", np.mean(np.square(test_y-0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90091c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we study convNets as classification\n",
    "# in this problem we study convNets as Regression\n",
    "# Deeplearning model for Regression\n",
    "\n",
    "# problem:\n",
    "#     input: sequence of images ---> we need to predict steering wheel angel\n",
    "#      -->this is the problem of Regression who we pose this problem in deeeplearning\n",
    "\n",
    "# we pose this problem in 2 ways\n",
    "\n",
    "\n",
    "# case1:\n",
    "#         input: images(discard sequ.of images) ---> predict real value\n",
    "#         For this convnets work very well(b/z it design specially for image processing)\n",
    "\n",
    "\n",
    "# case2:\n",
    "#         Input: video(sequence of images) --> predict sequence of real value\n",
    "#         for this we used the combination of CNN-RNN(LSTM)\n",
    "#         images ------> CNN ---->output will be vector representation----->LSTM------>Y^(predicted value)\n",
    "#          \n",
    "\n",
    "#        Actual self dirving car used very complext (CNN-RNN)\n",
    "\n",
    "\n",
    "\n",
    "# but we used case1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4bafedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END to END Model\n",
    "  # input: image ---->CNN model ---> predict steering angle \n",
    "    \n",
    "# Earlied people not use end-to-end model\n",
    "# 1:detect road\n",
    "# 2: detect lane\n",
    "# 3: detect angle\n",
    "# 4: detect rotaton\n",
    "# 5: detect cars\n",
    "# 6: detect breaker\n",
    "    \n",
    "# For every thing they have separate model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad93778",
   "metadata": {},
   "source": [
    "# Batch_load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5b3013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324\n",
      "9081\n"
     ]
    }
   ],
   "source": [
    "# before \n",
    "# 1: i load the data\n",
    "# 2: split and shuffle the data b/w train and test\n",
    "\n",
    "# Now batches of data\n",
    "\n",
    "# import cv2\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import random\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "# pointer will be point the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "# read data.txt\n",
    "with open(\"D:\\DataSet for ML\\Selfdriving_dataset\\data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"Selfdriving_dataset/\" + line.split()[0])\n",
    "#         print(xs)\n",
    "         #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1])* pi/180)\n",
    "#         print(ys)\n",
    "        \n",
    "        \n",
    "# get number of images:\n",
    "Total_num_images = len(xs)\n",
    "# print(Total_num_images)\n",
    "\n",
    "# get number of label image(steering wheel angel)\n",
    "# if number of images == number of label image\n",
    "# then we have no missing images\n",
    "\n",
    "num_lable_of_images = len(ys)\n",
    "# print(num_lable_of_images) \n",
    "\n",
    "\n",
    "# data shuffle into train_x and train_y, val_x and val_y\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "# print(len(train_ys))\n",
    "# print(val_ys)\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images =  len(val_xs)\n",
    "\n",
    "print(num_train_images)\n",
    "print(num_val_images)\n",
    "\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer+i) % num_train_images])))\n",
    "#          imge = Image.open(imageio.imread(train_xs[(train_batch_pointer+i) % num_train_images]))\n",
    "#         x_out.append = imge.resize\n",
    "        y_out.append([train_ys[(train_batch_pointer+i)%num_train_images]])\n",
    "        \n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "    \n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in random(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])))\n",
    "#         x_out.append(imageio.imresize(imageio.imread(val_xs[(val_batch_pointer + i) % num_val_images])))\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer  += batch_size\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4282dc",
   "metadata": {},
   "source": [
    "# End to End CNN model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e410b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import scipy\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,stride,stride,1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66,200,3])\n",
    "y_= tf.placeholder(tf.float32, shape=[None ,1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "# first convnet layer\n",
    "w_conv1 = weight_variable([5,5,3,24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conve1 = tf.nn.relu(conv2d(x_image, w_conv1, 2)+b_conv1)\n",
    "\n",
    "# 2nd convnet layer\n",
    "w_conv2 = weight_variable([5,5,24,36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conve2 = tf.nn.relu(conv2d(h_conve1, w_conv2, 2)+b_conv2)\n",
    "    \n",
    "#3rd convet layer\n",
    "w_conv3 = weight_variable([5,5,36,48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conve3 = tf.nn.relu(conv2d(h_conve2, w_conv3, 2)+b_conv3)\n",
    "\n",
    "# 4th convet layer\n",
    "w_conv4 = weight_variable([3,3,48,64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conve4 = tf.nn.relu(conv2d(h_conve3, w_conv4, 1)+b_conv4)\n",
    "\n",
    "# 5th convet layer\n",
    "w_conv5 = weight_variable([3,3,64,64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conve5 = tf.nn.relu(conv2d(h_conve4, w_conv5, 1)+b_conv5)\n",
    "\n",
    "\n",
    "\n",
    "# Full connected layer\n",
    "\n",
    "# 1 FC layer\n",
    "w_fc1 = weight_variable([1152,1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conve5,[-1,1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat,w_fc1)+ b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 2 FC layer\n",
    "w_fc2 = weight_variable([1164,100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop,w_fc2)+ b_fc2)\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "# 3 FC layer\n",
    "w_fc3 = weight_variable([100,50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, w_fc3)+ b_fc3)\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "\n",
    "# 4 FC layer\n",
    "w_fc4 = weight_variable([50,10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, w_fc4)+ b_fc4)\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "\n",
    "# output\n",
    "w_fc5 = weight_variable([10,1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.atan(tf.matmul(h_fc4_drop, w_fc5)+ b_fc5),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2553e8",
   "metadata": {},
   "source": [
    "# After building model \n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d492bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py:1769: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.misc' has no attribute 'imresize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(Total_num_images\u001b[38;5;241m/\u001b[39mbatch_size)):\n\u001b[1;32m---> 26\u001b[0m         xs , ys \u001b[38;5;241m=\u001b[39m \u001b[43mLoadTrainBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m         train_step\u001b[38;5;241m.\u001b[39mrun(feed_dict\u001b[38;5;241m=\u001b[39m{x:xs, y_:ys, keep_prob:\u001b[38;5;241m0.8\u001b[39m})\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mLoadTrainBatch\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m     y_out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch_size):\n\u001b[1;32m---> 64\u001b[0m         x_out\u001b[38;5;241m.\u001b[39mappend(\u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmisc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimresize\u001b[49m(scipy\u001b[38;5;241m.\u001b[39mmisc\u001b[38;5;241m.\u001b[39mimread(train_xs[(train_batch_pointer\u001b[38;5;241m+\u001b[39mi) \u001b[38;5;241m%\u001b[39m num_train_images])))\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#          imge = Image.open(imageio.imread(train_xs[(train_batch_pointer+i) % num_train_images]))\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#         x_out.append = imge.resize\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         y_out\u001b[38;5;241m.\u001b[39mappend([train_ys[(train_batch_pointer\u001b[38;5;241m+\u001b[39mi)\u001b[38;5;241m%\u001b[39mnum_train_images]])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imresize'"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "Logic_dir = './save'\n",
    "sess = tf.InteractiveSession()\n",
    "L2Normconst = 0.001\n",
    "train_vars = tf.trainable_variables()\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(y_ ,y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars])*L2Normconst\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create summay to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\",loss)\n",
    "\n",
    "saver = tf.train.Saver(write_version=saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "for epoch in range(epochs):\n",
    "    for i in range(int(Total_num_images/batch_size)):\n",
    "        xs , ys = LoadTrainBatch(batch_size)\n",
    "        train_step.run(feed_dict={x:xs, y_:ys, keep_prob:0.8})\n",
    "        if i % 10 == 0:\n",
    "            xs, ys = LoadValBatch(batch_size)\n",
    "            loss_val = loss.eval(feed_dict={x:xs, y_:ys, keep_prob:1.0})\n",
    "            \n",
    "# write logs to every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "    \n",
    "    if i % batch_size==0:\n",
    "        if not os.path.exists(Logic_dir):\n",
    "            os.makedirs(Logic_dir)\n",
    "        check_out_point = os.path.join(Logic_dir, \"model.ckpt\")\n",
    "        filename = saver.save(sess, check_out_point)\n",
    "print(\"Model save in file: %s\" % filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54568502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.m\n",
    "scipy.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4646846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
